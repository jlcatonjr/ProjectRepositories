{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6084/3822857466.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1TOTAL INCOME\"] = df[\"1INDIVIDUAL INCOME\"].add(df[\"1CORPORATE INCOME\"])\n",
      "/tmp/ipykernel_6084/3822857466.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1PROPERTY AND SPECIAL ASSESSMENTS\"] = df[[\"1PROPERTY\", \"1SPECIAL ASSESSMENTS\"]].sum(axis = 1)\n",
      "/tmp/ipykernel_6084/3822857466.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1DEFICIT\"] = df[\"1EXPENDITURE\"].sub(df[\"1GENERAL REVENUE\"])\n",
      "/tmp/ipykernel_6084/3822857466.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1TOTAL INCOME\"] = df[\"1INDIVIDUAL INCOME\"].add(df[\"1CORPORATE INCOME\"])\n",
      "/tmp/ipykernel_6084/3822857466.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1PROPERTY AND SPECIAL ASSESSMENTS\"] = df[[\"1PROPERTY\", \"1SPECIAL ASSESSMENTS\"]].sum(axis = 1)\n",
      "/tmp/ipykernel_6084/3822857466.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1DEFICIT\"] = df[\"1EXPENDITURE\"].sub(df[\"1GENERAL REVENUE\"])\n",
      "/tmp/ipykernel_6084/3822857466.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1TOTAL INCOME\"] = df[\"1INDIVIDUAL INCOME\"].add(df[\"1CORPORATE INCOME\"])\n",
      "/tmp/ipykernel_6084/3822857466.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1PROPERTY AND SPECIAL ASSESSMENTS\"] = df[[\"1PROPERTY\", \"1SPECIAL ASSESSMENTS\"]].sum(axis = 1)\n",
      "/tmp/ipykernel_6084/3822857466.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1DEFICIT\"] = df[\"1EXPENDITURE\"].sub(df[\"1GENERAL REVENUE\"])\n",
      "/tmp/ipykernel_6084/3822857466.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1TOTAL INCOME\"] = df[\"1INDIVIDUAL INCOME\"].add(df[\"1CORPORATE INCOME\"])\n",
      "/tmp/ipykernel_6084/3822857466.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1PROPERTY AND SPECIAL ASSESSMENTS\"] = df[[\"1PROPERTY\", \"1SPECIAL ASSESSMENTS\"]].sum(axis = 1)\n",
      "/tmp/ipykernel_6084/3822857466.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1DEFICIT\"] = df[\"1EXPENDITURE\"].sub(df[\"1GENERAL REVENUE\"])\n",
      "/tmp/ipykernel_6084/3822857466.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1TOTAL INCOME\"] = df[\"1INDIVIDUAL INCOME\"].add(df[\"1CORPORATE INCOME\"])\n",
      "/tmp/ipykernel_6084/3822857466.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1PROPERTY AND SPECIAL ASSESSMENTS\"] = df[[\"1PROPERTY\", \"1SPECIAL ASSESSMENTS\"]].sum(axis = 1)\n",
      "/tmp/ipykernel_6084/3822857466.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"1DEFICIT\"] = df[\"1EXPENDITURE\"].sub(df[\"1GENERAL REVENUE\"])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "from homebrewedFunctions.functions import *\n",
    "stack_dfs = pd.read_csv(\"StateGovFinances2005to2021.csv\", index_col = [\"State\", \"Year\", \"Format\"], low_memory =False).sort_index()\n",
    "panel_dfs_dict = {k:stack_dfs[stack_dfs.index.get_level_values(2)==k].reset_index().set_index([\"State\",\"Year\"]).sort_index() for k in stack_dfs.index.get_level_values(2).unique()}\n",
    "for key, df in panel_dfs_dict.items():\n",
    "    for col in df.columns:\n",
    "        if not is_numeric_dtype(df[col]):\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors = \"coerce\")\n",
    "                df[col] = df[col].fillna(0)\n",
    "                df[col] = df[col].astype(int)\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            df[col] = df[col].fillna(\"\")\n",
    "    df[\"1TOTAL INCOME\"] = df[\"1INDIVIDUAL INCOME\"].add(df[\"1CORPORATE INCOME\"])\n",
    "    df[\"1PROPERTY AND SPECIAL ASSESSMENTS\"] = df[[\"1PROPERTY\", \"1SPECIAL ASSESSMENTS\"]].sum(axis = 1)\n",
    "    df[\"1DEFICIT\"] = df[\"1EXPENDITURE\"].sub(df[\"1GENERAL REVENUE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>EFW</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AK</th>\n",
       "      <th>1985-01-01</th>\n",
       "      <td>8.04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">WY</th>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>8.12</td>\n",
       "      <td>3.997140e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>7.97</td>\n",
       "      <td>3.667550e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.217620e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.908060e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.017160e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1950 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   EFW           GDP\n",
       "State Year                          \n",
       "AK    1985-01-01  8.04           NaN\n",
       "      1986-01-01   NaN           NaN\n",
       "      1987-01-01   NaN           NaN\n",
       "      1988-01-01   NaN           NaN\n",
       "      1989-01-01   NaN           NaN\n",
       "...                ...           ...\n",
       "WY    2019-01-01  8.12  3.997140e+10\n",
       "      2020-01-01  7.97  3.667550e+10\n",
       "      2021-01-01   NaN  4.217620e+10\n",
       "      2022-01-01   NaN  4.908060e+10\n",
       "      2023-01-01   NaN  5.017160e+10\n",
       "\n",
       "[1950 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efwgdp = pd.read_csv(\"EFWGDPTaxes.csv\", parse_dates = [\"Year\"]).set_index([\"State\", \"Year\"]).sort_index()\n",
    "efwgdp[[\"EFW\", \"GDP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_keys = [\"GENERAL REVENUE\",\"GENERAL REVENUE FROM OWN SOURCES\", \"EXPENDITURE\", \"DEFICIT\", \n",
    "        \"FROM FEDERAL GOVERNMENT\", \"FROM STATE GOVERNMENT\", \"FROM LOCAL GOVERNMENTS\" ,\n",
    "        \"TAXES\", \"OTHER TAXES\", \"CURRENT CHARGES\", \"OTHER CHARGES\", 'INDIVIDUAL INCOME', 'CORPORATE INCOME', #'TOTAL INCOME',\n",
    "        \"PROPERTY\", \"SPECIAL ASSESSMENTS\"]#\"PROPERTY AND SPECIAL ASSESSMENTS\",  \n",
    "        # \"SALES AND GROSS RECEIPTS\", \"GENERAL SALES\", \"MOTOR FUEL\", \"GAS SUPPLY\", \"EDUCATION\", \"HIGHER EDUCATION\", \"PUBLIC WELFARE\"]\t\n",
    "\n",
    "keys = [\"GENERAL REVENUE\",\"GENERAL REVENUE FROM OWN SOURCES\", \"EXPENDITURE\", \"DEFICIT\", \n",
    "        \"FROM FEDERAL GOVERNMENT\", \"FROM STATE GOVERNMENT\", \"FROM LOCAL GOVERNMENTS\" ,\n",
    "        \"TAXES\", \"OTHER TAXES\", 'PROPERTY', 'SPECIAL ASSESSMENTS', 'PROPERTY AND SPECIAL ASSESSMENTS', 'SALES AND GROSS RECEIPTS', 'GENERAL SALES', 'SELECTIVE SALES', 'MOTOR FUEL', 'ALCOHOLIC BEVERAGE', \n",
    "        'TOBACCO PRODUCTS', 'PUBLIC UTILITIES', 'OTHER SELECTIVE SALES', 'INDIVIDUAL INCOME', 'CORPORATE INCOME', \"TOTAL INCOME\", 'MOTOR VEHICLE LICENSE', \n",
    "        'OTHER TAXES', 'CHARGES AND MISCELLANEOUS GENERAL  REVENUE', 'CURRENT CHARGES', 'EDUCATION', 'INSTITUTIONS  OF HIGHER EDUCATION', \n",
    "        'SCHOOL LUNCH SALES (GROSS)', 'HOSPITALS', 'HIGHWAYS', 'AIR TRANSPORTATION (AIRPORTS)', 'PARKING FACILITIES', 'SEA AND INLAND PORT FACILITIES', \n",
    "        'NATURAL RESOURCES', 'PARKS AND RECREATION', 'HOUSING AND COMMUNITY DEVELOPMENT', 'SEWERAGE', 'SOLID WASTE MANAGEMENT', 'OTHER CHARGES', \n",
    "        'MISCELLANEOUS GENERAL REVENUE', 'INTEREST EARNINGS',  'SALE OF PROPERTY', 'OTHER GENERAL REVENUE', 'UTILITY REVENUE', \n",
    "        'WATER SUPPLY', 'ELECTRIC POWER', 'GAS SUPPLY', 'TRANSIT', 'LIQUOR STORE REVENUE', 'INSURANCE TRUST REVENUE', 'UNEMPLOYMENT COMPENSATION', \n",
    "        'EMPLOYEE RETIREMENT', \"WORKERS' COMPENSATION\", 'OTHER INSURANCE TRUST REVENUE',\"EDUCATION\", \"HIGHER EDUCATION\", \"PUBLIC WELFARE\"]\n",
    "keys = [\"1\" + k for k in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dfs = {}\n",
    "keys = [\"GENERAL REVENUE\",\"GENERAL REVENUE FROM OWN SOURCES\", \"EXPENDITURE\", \"DEFICIT\", \n",
    "        \"FROM FEDERAL GOVERNMENT\", \"FROM STATE GOVERNMENT\", \"FROM LOCAL GOVERNMENTS\" ,\n",
    "        \"TAXES\", \"OTHER TAXES\", \"CURRENT CHARGES\", \"OTHER CHARGES\", 'INDIVIDUAL INCOME', 'CORPORATE INCOME', 'TOTAL INCOME',\n",
    "        \"PROPERTY\", \"SPECIAL ASSESSMENTS\", \"PROPERTY AND SPECIAL ASSESSMENTS\",  \n",
    "        \"SALES AND GROSS RECEIPTS\", \"GENERAL SALES\", \"MOTOR FUEL\", \"GAS SUPPLY\", \"EDUCATION\", \"HIGHER EDUCATION\", \"PUBLIC WELFARE\"]\t\n",
    "def set_plot_dfs(panel_dfs_dict, keys, efwgdp):\n",
    "    keys = [\"1\" + k for k in keys]\n",
    "    for key in panel_dfs_dict.keys():\n",
    "        plot_dfs[key] = {}\n",
    "        plot_dfs[key][\"Level\"] = panel_dfs_dict[key][keys].mul(10**3).copy()\n",
    "        plot_dfs[key][\"Level\"].rename(columns = {k:k.replace(\"1\", \"\").title() for k in plot_dfs[key][\"Level\"].keys()}, inplace = True)\n",
    "    #     plot_dfs[key][\"Level\"][\"Total Income\"] = plot_dfs[key][\"Level\"][\"Individual Income\"].add(plot_dfs[key][\"Level\"][\"Corporate Income\"])\n",
    "    #     plot_dfs[key][\"Level\"][\"Property and Special Assessments\"] = plot_dfs[key][\"Level\"][[\"Property\", \"Special Assessments\"]].sum(axis = 1)\n",
    "    #     plot_dfs[key][\"Level\"][\"Deficit\"] = plot_dfs[key][\"Level\"][\"Expenditure\"].sub(plot_dfs[key][\"Level\"][\"General Revenue\"])\n",
    "        plot_dfs[key][\"Level\"][\"GDP\"] = efwgdp[\"GDP\"]\n",
    "        plot_dfs[key][\"Level\"][\"Population\"] = efwgdp[\"Population\"]\n",
    "        plot_dfs[key][\"Percent of General Revenue\"] = plot_dfs[key][\"Level\"].apply(lambda x: pd.to_numeric(x).div(plot_dfs[key][\"Level\"][\"General Revenue\"]).mul(100))    \n",
    "        plot_dfs[key][\"Percent of GDP\"] = plot_dfs[key][\"Level\"].apply(lambda x: pd.to_numeric(x).div(plot_dfs[key][\"Level\"][\"GDP\"]).mul(100))\n",
    "        plot_dfs[key][\"Value of Per Capita\"] = plot_dfs[key][\"Level\"].apply(lambda x: pd.to_numeric(x).div(plot_dfs[key][\"Level\"][\"Population\"]))    \n",
    "        for key in plot_dfs.keys():\n",
    "            plot_dfs[key][\"Level\"][\"EFW\"] = efwgdp[\"EFW\"]\n",
    "    return plot_dfs\n",
    "plot_dfs = set_plot_dfs(panel_dfs_dict, keys, efwgdp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key, p_dfs in plot_dfs.items():\n",
    "    for p_dfskey, df in p_dfs.items():\n",
    "        map_figs = {}\n",
    "        create_scatter_dropdown(df, \n",
    "                                filename = f\"outputs/ScatterAppIncomePropertyAssessmentSalesFuelTaxesPctTotalRevenue{key}{p_dfskey}.html\", \n",
    "                                show_fig = False)\n",
    "        for name in df.keys():\n",
    "            map_figs[name] = create_map(df.reset_index(), name, time_name = \"Year\")\n",
    "        combined_fig = combine_map_figs(map_figs)\n",
    "        combined_fig.write_html(f\"outputs/AllMapsByVariableAndYear{key}{p_dfskey}.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dfs = {}\n",
    "keys = [\"GENERAL REVENUE\",\"GENERAL REVENUE FROM OWN SOURCES\", \"EXPENDITURE\", \"DEFICIT\", \n",
    "        \"FROM FEDERAL GOVERNMENT\", \"FROM STATE GOVERNMENT\", \"FROM LOCAL GOVERNMENTS\" , \"INTERGOVERNMENTAL REVENUE\",\n",
    "        \"TAXES\", \"OTHER TAXES\", 'PROPERTY', 'SPECIAL ASSESSMENTS', 'PROPERTY AND SPECIAL ASSESSMENTS', 'SALES AND GROSS RECEIPTS', 'GENERAL SALES', 'SELECTIVE SALES', 'MOTOR FUEL', 'ALCOHOLIC BEVERAGE', \n",
    "        'TOBACCO PRODUCTS', 'PUBLIC UTILITIES', 'OTHER SELECTIVE SALES', 'INDIVIDUAL INCOME', 'CORPORATE INCOME', \"TOTAL INCOME\", 'MOTOR VEHICLE LICENSE', \n",
    "        'OTHER TAXES', 'CHARGES AND MISCELLANEOUS GENERAL  REVENUE', 'CURRENT CHARGES', 'EDUCATION', 'INSTITUTIONS  OF HIGHER EDUCATION', \n",
    "        'SCHOOL LUNCH SALES (GROSS)', 'HOSPITALS', 'HIGHWAYS', 'AIR TRANSPORTATION (AIRPORTS)', 'PARKING FACILITIES', 'SEA AND INLAND PORT FACILITIES', \n",
    "        'NATURAL RESOURCES', 'PARKS AND RECREATION', 'HOUSING AND COMMUNITY DEVELOPMENT', 'SEWERAGE', 'SOLID WASTE MANAGEMENT', 'OTHER CHARGES', \n",
    "        'MISCELLANEOUS GENERAL REVENUE', 'INTEREST EARNINGS',  'SALE OF PROPERTY', 'OTHER GENERAL REVENUE', 'UTILITY REVENUE', \n",
    "        'WATER SUPPLY', 'ELECTRIC POWER', 'GAS SUPPLY', 'TRANSIT', 'LIQUOR STORE REVENUE', 'INSURANCE TRUST REVENUE', 'UNEMPLOYMENT COMPENSATION', \n",
    "        'EMPLOYEE RETIREMENT', \"WORKERS' COMPENSATION\", 'OTHER INSURANCE TRUST REVENUE',\"EDUCATION\", \"HIGHER EDUCATION\", \"PUBLIC WELFARE\"]\n",
    "plot_dfs = set_plot_dfs(panel_dfs_dict, keys, efwgdp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, p_dfs in plot_dfs.items():\n",
    "    figs = {key: line_dropdown(dataframe) for key, dataframe in p_dfs.items()}\n",
    "    fig = dict_of_figs_to_dropdown_fig(figs, show_fig = False,\n",
    "                                    use_sliders = True)\n",
    "    # fig.show()\n",
    "    fig.write_html(f\"outputs/LineplotAppStateFinancesAsPercentRevenuePercentGDPAndPerCapitaFigs{key}.html\")\n",
    "\n",
    "# fig = line_dropdown(pct_df)\n",
    "# fig.write_html(\"line_dropdown.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2005\n",
    "gov_keys = [\"Local government amount\",'State & local government amount', 'State government amount']\n",
    "states = plot_dfs[gov_keys[0]][\"Level\"].index.get_level_values(\"State\").unique()\n",
    "areas = {\"Revenue Source by Government\" : [\"General Revenue From Own Sources\", \"From Federal Government\", \"From State Government\", \"From Local Governments\"],\n",
    "         \n",
    "    #  Omit revenue sources according to distinction of subcomponents in revenue data \n",
    "    #  Some sources additionally needed to be removed as their values perfectly explained\n",
    "    #  accounting that sums to greater than 100 percent\n",
    "     \n",
    "         \"Taxes\": [\"Intergovernmental Revenue\", 'Property', 'Sales And Gross Receipts', \n",
    "                   'Individual Income', 'Corporate Income', 'Motor Vehicle License', 'Other Taxes', \n",
    "                #    'Charges And Miscellaneous General  Revenue', \n",
    "                   'Current Charges', \n",
    "                #    'Education', 'Institutions  Of Higher Education', 'School Lunch Sales (Gross)',\n",
    "                #      'Hospitals', 'Highways', 'Air Transportation (Airports)', 'Parking Facilities', 'Sea And Inland Port Facilities', 'Natural Resources',\n",
    "                #       'Parks And Recreation', 'Housing And Community Development', 'Sewerage', 'Solid Waste Management', 'Other Charges', \n",
    "                    #   'Miscellaneous General Revenue', \n",
    "                      'Interest Earnings', 'Special Assessments', 'Sale Of Property', 'Other General Revenue']}\n",
    "                    #   'Utility Revenue']}\n",
    "                    #   'Water Supply', 'Electric Power', 'Gas Supply', 'Transit', \n",
    "                    # 'Liquor Store Revenue',\n",
    "                #    'Insurance Trust Revenue',\n",
    "                #    'Unemployment Compensation', 'Employee Retirement', \"Workers' Compensation\", 'Other Insurance Trust Revenue']}\n",
    "figs = {}\n",
    "for key in gov_keys:\n",
    "    figs[key] = {}\n",
    "    for form in [\"Level\", \"Percent of General Revenue\", \"Percent of GDP\", \"Value Per Capita\"]:\n",
    "        figs[key][form] = {}\n",
    "        df = plot_dfs[key][form].copy()\n",
    "        df = df.reset_index().melt(id_vars=[\"State\",\"Year\"], \n",
    "            var_name=\"Name\", \n",
    "            value_name=\"Value\")\n",
    "        df = df.set_index([\"State\", \"Year\"]).round(2)\n",
    "        for components_group, components in areas.items():\n",
    "\n",
    "\n",
    "            figs[key][form][components_group] = {}\n",
    "\n",
    "            for state in states:\n",
    "                plot_df = df.loc[state].reset_index()#.loc[start_year:].reset_index()\n",
    "                plot_df = plot_df[plot_df[\"Name\"].isin(components)].dropna()\n",
    "                plot_df[\"Value\"] = pd.to_numeric(plot_df[\"Value\"])\n",
    "                title_key = f\"{form}<br>{key} {components_group}<br>{state}\"\n",
    "                px_fig = px.area(\n",
    "                    plot_df, x=\"Year\", y=\"Value\", color=\"Name\", title = title_key)\n",
    "\n",
    "                figs[key][form][components_group][state] = px_fig\n",
    "            figs[key][form][components_group]  = dict_of_figs_to_dropdown_fig(figs[key][form][components_group] , show_fig = False,\n",
    "                                        use_sliders = True)\n",
    "\n",
    "            figs[key][form][components_group].write_html(f\"outputs/{key}{form}{components_group}Figs.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
