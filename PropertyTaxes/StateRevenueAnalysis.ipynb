{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import datetime\n",
    "from homebrewedFunctions.functions import *\n",
    "all_keys = pd.read_csv(\"StateGovFinances2005to2021.csv\", index_col = [\"State\", \"Year\", \"Format\"], low_memory =False).sort_index().keys()\n",
    "all_keys = [k for k in all_keys if \"NAN\" not in k]\n",
    "keys_dict = {\"Revenue\": all_keys[:52],\n",
    "            \"Expenditure\": [k for k in all_keys[52:121] if \"CAPITAL OUTLAY\" not in k],\n",
    "            \"Debt\": [k for k in all_keys[121:] if \"CAPITAL OUTLAY\" not in k]}\n",
    "            \n",
    "\n",
    "stack_dfs = {\"Expenditure\": pd.read_csv(\"StateGovFinances2005to2021.csv\", index_col = [\"State\", \"Year\", \"Format\"], usecols = [\"State\", \"Year\", \"Format\", \"1GENERAL REVENUE\", \"1DEBT OUTSTANDING\"] + keys_dict[\"Expenditure\"], low_memory =False).sort_index(),\n",
    "             \"Revenue\":pd.read_csv(\"StateGovFinances2005to2021.csv\", index_col = [\"State\", \"Year\", \"Format\"], usecols = [\"State\", \"Year\", \"Format\", \"1EXPENDITURE\", \"1DEBT OUTSTANDING\"] + keys_dict[\"Revenue\"], low_memory =False).sort_index(),\n",
    "             \"Debt\":pd.read_csv(\"StateGovFinances2005to2021.csv\", index_col = [\"State\", \"Year\", \"Format\"], usecols = [\"State\", \"Year\", \"Format\", \"1EXPENDITURE\", \"1GENERAL REVENUE\"] + keys_dict[\"Debt\"], low_memory =False).sort_index()}\n",
    "\n",
    "panel_dfs_dict = {}\n",
    "for rev_exp in stack_dfs.keys():\n",
    "    panel_dfs_dict[rev_exp] = {}\n",
    "    for k in stack_dfs[rev_exp].index.get_level_values(2).unique():\n",
    "        panel_dfs_dict[rev_exp][k] = stack_dfs[rev_exp][stack_dfs[rev_exp].index.get_level_values(2)==k].reset_index().set_index([\"State\",\"Year\"]).sort_index()\n",
    "        del panel_dfs_dict[rev_exp][k][\"Format\"]\n",
    "    panel_dfs_dict[rev_exp] = {k:panel_dfs_dict[rev_exp][k] for k in [\"Local government amount\",'State & local government amount', 'State government amount']}\n",
    "\n",
    "for key, dct in panel_dfs_dict.items():\n",
    "    for k, df in dct.items():\n",
    "        for col in df.columns:\n",
    "            if is_numeric_dtype(df[col]):\n",
    "                df[col] = df[col].fillna(0)\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    df[col] = pd.to_numeric(df[col], errors = \"coerce\").fillna(0).astype(int)\n",
    "                except:\n",
    "                    pass\n",
    "        if key == \"Revenue\":\n",
    "            df[\"1TOTAL INCOME\"] = df[\"1INDIVIDUAL INCOME\"].add(df[\"1CORPORATE INCOME\"])\n",
    "            df[\"1PROPERTY AND SPECIAL ASSESSMENTS\"] = df[[\"1PROPERTY\", \"1SPECIAL ASSESSMENTS\"]].sum(axis = 1)\n",
    "            df[\"1DEFICIT\"] = df[\"1EXPENDITURE\"].sub(df[\"1GENERAL REVENUE\"])\n",
    "            \n",
    "        # warning indicates that copying dataframe will defragment it;\n",
    "        #  not sure if this actually fixes the problem\n",
    "        df = df.copy()                \n",
    "cpi_code = {\"CPI\":\"CPIAUCSL\"}\n",
    "start = datetime.datetime(1947,1,1)\n",
    "end = datetime.datetime.now()\n",
    "cpi = gather_data(cpi_code, start, end, freq = \"A\").reset_index().rename(columns = {\"DATE\": \"Year\"})\n",
    "cpi[\"Year\"] = pd.to_datetime(cpi[\"Year\"].astype(str).str[:4], format = \"%Y\")\n",
    "cpi[\"Year\"] = cpi[\"Year\"].astype(str)\n",
    "cpi.set_index(\"Year\", inplace = True)\n",
    "cpi[\"CPI\"] = cpi[\"CPI\"].div(cpi[\"CPI\"].iloc[-2]).astype(float)\n",
    "efnagdp = pd.read_csv(\"EFNAGDPTaxes.csv\", parse_dates = [\"Year\"]).set_index([\"State\", \"Year\"]).sort_index()\n",
    "map_keys = [\"GENERAL REVENUE\",\"GENERAL REVENUE FROM OWN SOURCES\", \"EXPENDITURE\", \"DEFICIT\", \n",
    "        \"FROM FEDERAL GOVERNMENT\", \"FROM STATE GOVERNMENT\", \"FROM LOCAL GOVERNMENTS\" ,\n",
    "        \"TAXES\", \"OTHER TAXES\", \"CURRENT CHARGES\", \"OTHER CHARGES\", 'INDIVIDUAL INCOME', 'CORPORATE INCOME', #'TOTAL INCOME',\n",
    "        \"PROPERTY\", \"SPECIAL ASSESSMENTS\"]\n",
    "\n",
    "# keys = [\"GENERAL REVENUE\",\"GENERAL REVENUE FROM OWN SOURCES\", \"EXPENDITURE\", \"DEFICIT\", \n",
    "#         \"FROM FEDERAL GOVERNMENT\", \"FROM STATE GOVERNMENT\", \"FROM LOCAL GOVERNMENTS\" ,\n",
    "#         \"TAXES\", \"OTHER TAXES\", \"CURRENT CHARGES\", \"OTHER CHARGES\", 'INDIVIDUAL INCOME', 'CORPORATE INCOME', 'TOTAL INCOME',\n",
    "#         \"PROPERTY\", \"SPECIAL ASSESSMENTS\", \"PROPERTY AND SPECIAL ASSESSMENTS\",  \n",
    "#         \"SALES AND GROSS RECEIPTS\", \"GENERAL SALES\", \"MOTOR FUEL\", \"GAS SUPPLY\", \"EDUCATION\", \"HIGHER EDUCATION\", \"PUBLIC WELFARE\"]\t\n",
    "\n",
    "\n",
    "def set_plot_dfs(panel_dfs_dict, keys, efnagdp, cpi):\n",
    "    # keys = [\"1\" + k for k in keys]\n",
    "    plot_dfs = {}\n",
    "    for key in panel_dfs_dict.keys():\n",
    "        plot_dfs[key] = {}\n",
    "        plot_dfs[key][\"Level\"] = panel_dfs_dict[key].mul(10**3).copy()\n",
    "        plot_dfs[key][\"Level\"].rename(columns = {k:k.replace(\"1\", \"\").title() for k in plot_dfs[key][\"Level\"].keys()}, inplace = True)\n",
    "    #     plot_dfs[key][\"Level\"][\"Total Income\"] = plot_dfs[key][\"Level\"][\"Individual Income\"].add(plot_dfs[key][\"Level\"][\"Corporate Income\"])\n",
    "    #     plot_dfs[key][\"Level\"][\"Property and Special Assessments\"] = plot_dfs[key][\"Level\"][[\"Property\", \"Special Assessments\"]].sum(axis = 1)\n",
    "    #     plot_dfs[key][\"Level\"][\"Deficit\"] = plot_dfs[key][\"Level\"][\"Expenditure\"].sub(plot_dfs[key][\"Level\"][\"General Revenue\"])\n",
    "        plot_dfs[key][\"Level\"][\"GDP\"] = efnagdp[\"GDP\"]\n",
    "        plot_dfs[key][\"Real Level\"] = plot_dfs[key][\"Level\"].div(cpi[\"CPI\"], level = \"Year\", axis = 0)\n",
    "        plot_dfs[key][\"Level\"][\"Population\"] = efnagdp[\"Population\"]\n",
    "        plot_dfs[key][\"Percent of General Revenue\"] = plot_dfs[key][\"Level\"].apply(lambda x: pd.to_numeric(x).div(plot_dfs[key][\"Level\"][\"General Revenue\"]).mul(100))    \n",
    "        plot_dfs[key][\"Percent of GDP\"] = plot_dfs[key][\"Level\"].apply(lambda x: pd.to_numeric(x).div(plot_dfs[key][\"Level\"][\"GDP\"]).mul(100))\n",
    "        \n",
    "        plot_dfs[key][\"Real Value Per Capita\"] = plot_dfs[key][\"Real Level\"].apply(lambda x: pd.to_numeric(x).div(plot_dfs[key][\"Level\"][\"Population\"]))    \n",
    "        for k in plot_dfs[key].keys():\n",
    "            plot_dfs[key][k][\"EFNA\"] = efnagdp[\"EFNA\"]\n",
    "    return plot_dfs\n",
    "plot_dfs = {}\n",
    "\n",
    "for key in panel_dfs_dict.keys():\n",
    "    plot_dfs[key] = set_plot_dfs(panel_dfs_dict[key], keys_dict[key], efnagdp, cpi)\n",
    "\n",
    "\n",
    "import os\n",
    "for revexp_key in plot_dfs.keys():\n",
    "    for key in plot_dfs[revexp_key].keys():\n",
    "        try:\n",
    "            os.mkdir(f\"outputs/{key}\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "regions_df = pd.read_csv(\"USCensusRegions.csv\")#.set_index(\"State\")\n",
    "# scatter_figs = {}\n",
    "for revexp_key in plot_dfs.keys():\n",
    "    for key, p_dfs in plot_dfs[revexp_key].items():\n",
    "        for p_dfskey, df in p_dfs.items():\n",
    "            map_figs = {}\n",
    "            html_path = f\"outputs/{key}/ScatterPlots{revexp_key}{key}{p_dfskey}.html\"\n",
    "            create_scatter_dropdown(df, regions_df=regions_df,\n",
    "                                    filename = html_path, \n",
    "                                    show_fig = False)\n",
    "            for name in df.keys():\n",
    "                map_figs[name] = create_map(df.reset_index(), name, time_name = \"Year\")\n",
    "            combined_map_fig = combine_map_figs(map_figs)\n",
    "            html_path = f\"outputs/{key}/MapPlotsByVariableAndYear{revexp_key}{key}{p_dfskey}.html\"\n",
    "            combined_map_fig.write_html(html_path)\n",
    "regions_df = pd.read_csv(\"USCensusRegions.csv\")#.set_index(\"State\")\n",
    "\n",
    "for revexp_key in plot_dfs.keys():\n",
    "    for key, p_dfs in plot_dfs[revexp_key].items():\n",
    "        # figs = {k: line_dropdown(dataframe, regions_df) for k, dataframe in p_dfs.items()}\n",
    "        # fig = dict_of_line_figs_to_dropdown_fig(figs, show_fig = False, use_sliders = True)\n",
    "        filename = f\"outputs/{key}/LinePlotsStateFinances{revexp_key}{key}.html\"\n",
    "        fig = line_dropdown(p_dfs, regions_df)\n",
    "        fig.write_html(filename, config=dict(displayModeBar=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'reset_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m figs[key][form] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     25\u001b[0m df \u001b[38;5;241m=\u001b[39m plot_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 26\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mmelt(id_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     27\u001b[0m     var_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     28\u001b[0m     value_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mset_index([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     30\u001b[0m states \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_level_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39munique()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'reset_index'"
     ]
    }
   ],
   "source": [
    "### NEED TO IDENTIFY SUBCOMPONENTS OF EXPENDITURES\n",
    "\n",
    "start_year = 2005\n",
    "areas = {\"Revenue\":{\"Revenue Source by Government\" : [\"General Revenue From Own Sources\", \"From Federal Government\", \"From State Government\", \"From Local Governments\"],\n",
    "         \"Taxes\": [\"Intergovernmental Revenue\", 'Property', 'Sales And Gross Receipts', \n",
    "                   'Individual Income', 'Corporate Income', 'Motor Vehicle License', 'Other Taxes', \n",
    "                   'Current Charges', 'Interest Earnings', 'Special Assessments', 'Sale Of Property', 'Other General Revenue']},\n",
    "        \"Expenditure\": {\"Expenditures\":[\n",
    "            \"Intergovernmental Expenditure\", \"Education\", \"Libraries\", \"Public Welfare\", \"Hospitals\", \n",
    "            \"Health\", \"Health\", \"Employment Security Administration\", \"Veterans' Services\",\n",
    "            \"Highways\", \"Air Transportation (Airports)\", \"Parking Facilities\", \"Sea and Inland Port Facilities\",\n",
    "            \"Police Protection\", \"Fire Protection\", \"Correction\", \"Protective Inspection And Regulation\",\n",
    "            \"Natural Resources\", \"Parks and Recreation\", \"Housing and Community Development\", \"Sewarage\",\n",
    "            \"Solid Waste Management\", \"Financial Administration\",\"Judicial And Legal\", \"General Public Buildings\",\n",
    "            \"Other Governmental Administration\", \"Interest On General Debt\", \"Miscellaneous Commercial Activities\",\n",
    "            \"Other And Unallocable\", \"Utility Expenditure\", \"Liquor Stores Expenditure\", \n",
    "            \"Insurance Trust Expenditure\"]},\n",
    "            # \"Debt\": {\"\"}\n",
    "}\n",
    "figs = {}\n",
    "for revexp_key in plot_dfs.keys():\n",
    "    for key, p_dfs in plot_dfs[revexp_key].items():\n",
    "        figs[key] = {}\n",
    "        for form, plot_df in p_dfs.items():# [\"Level\", \"Real Level\", \"Percent of General Revenue\", \"Percent of GDP\", \"Real Value Per Capita\"]:\n",
    "            figs[key][form] = {}\n",
    "            df = plot_df.copy()\n",
    "            df = df.reset_index().melt(id_vars=[\"State\",\"Year\"],\n",
    "                var_name=\"Name\", \n",
    "                value_name=\"Value\")\n",
    "            df = df.set_index([\"State\", \"Year\"]).round(2)\n",
    "            states = df.index.get_level_values(\"State\").unique()\n",
    "\n",
    "            for components_group, components in areas[key].items():\n",
    "\n",
    "\n",
    "                figs[key][form][components_group] = {}\n",
    "\n",
    "                for state in states:\n",
    "                    plot_df = df.loc[state].reset_index()#.loc[start_year:].reset_index()\n",
    "                    plot_df = plot_df[plot_df[\"Name\"].isin(components)].dropna()\n",
    "                    plot_df[\"Value\"] = pd.to_numeric(plot_df[\"Value\"])\n",
    "                    title_key = f\"{components_group} {key}<br>{form}<br>{state}\"\n",
    "                    px_fig = px.area(\n",
    "                        plot_df, x=\"Year\", y=\"Value\", color=\"Name\", title = title_key)\n",
    "\n",
    "                    figs[key][form][components_group][state] = px_fig\n",
    "                figs[key][form][components_group]  = dict_of_figs_to_dropdown_fig(figs[key][form][components_group], \n",
    "                                                                                show_fig = False,\n",
    "                                                                                use_sliders = True)\n",
    "                figs[key][form][components_group].write_html(f\"outputs/{key}/AreaPlots{rev_exp_key}{key}{form}{components_group}Figs.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1GENERAL REVENUE\n",
      "1 1INTERGOVERNMENTAL REVENUE\n",
      "2 1FROM FEDERAL GOVERNMENT\n",
      "3 1FROM STATE GOVERNMENT\n",
      "4 1FROM LOCAL GOVERNMENTS\n",
      "5 1GENERAL REVENUE FROM OWN SOURCES\n",
      "6 1TAXES\n",
      "7 1PROPERTY\n",
      "8 1SALES AND GROSS RECEIPTS\n",
      "9 1GENERAL SALES\n",
      "10 1SELECTIVE SALES\n",
      "11 1MOTOR FUEL\n",
      "12 1ALCOHOLIC BEVERAGE\n",
      "13 1TOBACCO PRODUCTS\n",
      "14 1PUBLIC UTILITIES\n",
      "15 1OTHER SELECTIVE SALES\n",
      "16 1INDIVIDUAL INCOME\n",
      "17 1CORPORATE INCOME\n",
      "18 1MOTOR VEHICLE LICENSE\n",
      "19 1OTHER TAXES\n",
      "20 1CHARGES AND MISCELLANEOUS GENERAL  REVENUE\n",
      "21 1CURRENT CHARGES\n",
      "22 1EDUCATION\n",
      "23 1INSTITUTIONS  OF HIGHER EDUCATION\n",
      "24 1SCHOOL LUNCH SALES (GROSS)\n",
      "25 1HOSPITALS\n",
      "26 1HIGHWAYS\n",
      "27 1AIR TRANSPORTATION (AIRPORTS)\n",
      "28 1PARKING FACILITIES\n",
      "29 1SEA AND INLAND PORT FACILITIES\n",
      "30 1NATURAL RESOURCES\n",
      "31 1PARKS AND RECREATION\n",
      "32 1HOUSING AND COMMUNITY DEVELOPMENT\n",
      "33 1SEWERAGE\n",
      "34 1SOLID WASTE MANAGEMENT\n",
      "35 1OTHER CHARGES\n",
      "36 1MISCELLANEOUS GENERAL REVENUE\n",
      "37 1INTEREST EARNINGS\n",
      "38 1SPECIAL ASSESSMENTS\n",
      "39 1SALE OF PROPERTY\n",
      "40 1OTHER GENERAL REVENUE\n",
      "41 1UTILITY REVENUE\n",
      "42 1WATER SUPPLY\n",
      "43 1ELECTRIC POWER\n",
      "44 1GAS SUPPLY\n",
      "45 1TRANSIT\n",
      "46 1LIQUOR STORE REVENUE\n",
      "47 1INSURANCE TRUST REVENUE\n",
      "48 1UNEMPLOYMENT COMPENSATION\n",
      "49 1EMPLOYEE RETIREMENT\n",
      "50 1WORKERS' COMPENSATION\n",
      "51 1OTHER INSURANCE TRUST REVENUE\n",
      "52 1EXPENDITURE\n",
      "53 1INTERGOVERNMENTAL EXPENDITURE\n",
      "54 1DIRECT EXPENDITURE\n",
      "55 1CURRENT OPERATIONS\n",
      "56 1CAPITAL OUTLAY\n",
      "57 1CONSTRUCTION\n",
      "58 1OTHER CAPITAL OUTLAY\n",
      "59 1ASSISTANCE AND SUBSIDIES\n",
      "60 1INTEREST ON DEBT\n",
      "61 1INSURANCE BENEFITS AND REPAYMENTS\n",
      "62 1EXHIBIT: SALARIES AND WAGES\n",
      "63 1DIRECT EXPENDITURE BY FUNCTION\n",
      "64 1DIRECT GENERAL EXPENDITURE\n",
      "65 2CAPITAL OUTLAY\n",
      "66 1OTHER DIRECT GENERAL EXPENDITURE\n",
      "67 2EDUCATION\n",
      "68 3CAPITAL OUTLAY\n",
      "69 1HIGHER EDUCATION\n",
      "70 4CAPITAL OUTLAY\n",
      "71 1ELEMENTARY & SECONDARY\n",
      "72 5CAPITAL OUTLAY\n",
      "73 1OTHER EDUCATION\n",
      "74 1LIBRARIES\n",
      "75 1PUBLIC WELFARE\n",
      "76 1CASH ASSISTANCE PAYMENTS\n",
      "77 1VENDOR PAYMENTS\n",
      "78 1OTHER PUBLIC WELFARE\n",
      "79 2HOSPITALS\n",
      "80 6CAPITAL OUTLAY\n",
      "81 1HEALTH\n",
      "82 1EMPLOYMENT SECURITY ADMINISTRATION\n",
      "83 1VETERANS' SERVICES\n",
      "84 2HIGHWAYS\n",
      "85 7CAPITAL OUTLAY\n",
      "86 2AIR TRANSPORTATION (AIRPORTS)\n",
      "87 2PARKING FACILITIES\n",
      "88 2SEA AND INLAND PORT FACILITIES\n",
      "89 1POLICE PROTECTION\n",
      "90 1FIRE PROTECTION\n",
      "91 1CORRECTION\n",
      "92 8CAPITAL OUTLAY\n",
      "93 1PROTECTIVE INSPECTION AND REGULATION\n",
      "94 2NATURAL RESOURCES\n",
      "95 9CAPITAL OUTLAY\n",
      "96 2PARKS AND RECREATION\n",
      "97 10CAPITAL OUTLAY\n",
      "98 2HOUSING AND COMMUNITY DEVELOPMENT\n",
      "99 2SEWERAGE\n",
      "100 11CAPITAL OUTLAY\n",
      "101 2SOLID WASTE MANAGEMENT\n",
      "102 12CAPITAL OUTLAY\n",
      "103 1JUDICIAL AND LEGAL\n",
      "104 1GENERAL PUBLIC BUILDINGS\n",
      "105 1OTHER GOVERNMENTAL ADMINISTRATION\n",
      "106 1INTEREST ON GENERAL DEBT\n",
      "107 1MISCELLANEOUS COMMERCIAL ACTIVITIES\n",
      "108 1OTHER AND UNALLOCABLE\n",
      "109 1UTILITY EXPENDITURE\n",
      "110 13CAPITAL OUTLAY\n",
      "111 2WATER SUPPLY\n",
      "112 2ELECTRIC POWER\n",
      "113 2GAS SUPPLY\n",
      "114 2TRANSIT\n",
      "115 1LIQUOR STORE EXPENDITURE\n",
      "116 1INSURANCE TRUST EXPENDITURE\n",
      "117 2UNEMPLOYMENT COMPENSATION\n",
      "118 2EMPLOYEE RETIREMENT\n",
      "119 2WORKERS' COMPENSATION\n",
      "120 1OTHER INSURANCE TRUST\n",
      "121 1DEBT OUTSTANDING\n",
      "122 1SHORT-TERM\n",
      "123 1LONG-TERM\n",
      "124 1PUBLIC DEBT FOR PRIVATE PURPOSES\n",
      "125 1LONG-TERM DEBT ISSUED\n",
      "126 1LONG-TERM DEBT RETIRED\n",
      "127 1CASH AND SECURITY HOLDINGS\n",
      "128 1INSURANCE TRUST FUNDS\n",
      "129 3UNEMPLOYMENT COMPENSATION\n",
      "130 3EMPLOYEE RETIREMENT\n",
      "131 3WORKERS' COMPENSATION\n",
      "132 1MISCELLANEOUS\n",
      "133 1OTHER THAN INSURANCE TRUST FUNDS\n",
      "134 1OFFSETS TO DEBT\n",
      "135 1BOND FUNDS\n",
      "136 1OTHER\n",
      "137 1SOCIAL INSURANCE ADMINISTRATION\n",
      "138 1INSURANCE TRUST REVENUE2\n",
      "139 1CHARGES AND MISCELLANEOUS GENERAL REVENUE\n",
      "140 1REVENUE\n"
     ]
    }
   ],
   "source": [
    "for i, k in enumerate(all_keys):\n",
    "    print(i, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import datetime\n",
    "from homebrewedFunctions.functions import *\n",
    "stack_dfs = pd.read_csv(\"StateGovFinances2005to2021.csv\", index_col = [\"State\", \"Year\", \"Format\"], low_memory =False).sort_index()\n",
    "panel_dfs_dict = {k:stack_dfs[stack_dfs.index.get_level_values(2)==k].reset_index().set_index([\"State\",\"Year\"]).sort_index() for k in stack_dfs.index.get_level_values(2).unique()}\n",
    "panel_dfs_dict = {k:panel_dfs_dict[k] for k in [\"Local government amount\",'State & local government amount', 'State government amount']}\n",
    "# panel_dfs_dict[\"State government amount\"][]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9980/2555311391.py:11: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_9980/2555311391.py:12: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_9980/2555311391.py:13: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_9980/2555311391.py:11: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_9980/2555311391.py:12: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_9980/2555311391.py:13: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_9980/2555311391.py:11: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_9980/2555311391.py:12: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_9980/2555311391.py:13: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, df in panel_dfs_dict.items():\n",
    "    for col in df.columns:\n",
    "        if is_numeric_dtype(df[col]):\n",
    "            df[col] = df[col].fillna(0)\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors = \"coerce\").fillna(0).astype(int)\n",
    "            except:\n",
    "                pass\n",
    "    df[\"1TOTAL INCOME\"] = df[\"1INDIVIDUAL INCOME\"].add(df[\"1CORPORATE INCOME\"])\n",
    "    df[\"1PROPERTY AND SPECIAL ASSESSMENTS\"] = df[[\"1PROPERTY\", \"1SPECIAL ASSESSMENTS\"]].sum(axis = 1)\n",
    "    df[\"1DEFICIT\"] = df[\"1EXPENDITURE\"].sub(df[\"1GENERAL REVENUE\"])\n",
    "    # warning indicates that copying dataframe will defragment it;\n",
    "    #  not sure if this actually fixes the problem\n",
    "    df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1947-01-01</th>\n",
       "      <td>0.073290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-01-01</th>\n",
       "      <td>0.078913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-01-01</th>\n",
       "      <td>0.078140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-01</th>\n",
       "      <td>0.078971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951-01-01</th>\n",
       "      <td>0.085242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>0.849509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>0.889285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>0.960354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>1.024202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CPI\n",
       "Year                \n",
       "1947-01-01  0.073290\n",
       "1948-01-01  0.078913\n",
       "1949-01-01  0.078140\n",
       "1950-01-01  0.078971\n",
       "1951-01-01  0.085242\n",
       "...              ...\n",
       "2020-01-01  0.849509\n",
       "2021-01-01  0.889285\n",
       "2022-01-01  0.960354\n",
       "2023-01-01  1.000000\n",
       "2024-01-01  1.024202\n",
       "\n",
       "[78 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi_code = {\"CPI\":\"CPIAUCSL\"}\n",
    "start = datetime.datetime(1947,1,1)\n",
    "end = datetime.datetime.now()\n",
    "cpi = gather_data(cpi_code, start, end, freq = \"A\").reset_index().rename(columns = {\"DATE\": \"Year\"})\n",
    "cpi[\"Year\"] = pd.to_datetime(cpi[\"Year\"].astype(str).str[:4], format = \"%Y\")\n",
    "cpi[\"Year\"] = cpi[\"Year\"].astype(str)\n",
    "cpi.set_index(\"Year\", inplace = True)\n",
    "cpi[\"CPI\"] = cpi[\"CPI\"].div(cpi[\"CPI\"].iloc[-2]).astype(float)\n",
    "cpi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>EFNA</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AK</th>\n",
       "      <th>1985-01-01</th>\n",
       "      <td>8.04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">WY</th>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>8.12</td>\n",
       "      <td>3.997140e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>7.97</td>\n",
       "      <td>3.667550e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.217620e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.908060e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.017160e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1950 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  EFNA           GDP\n",
       "State Year                          \n",
       "AK    1985-01-01  8.04           NaN\n",
       "      1986-01-01   NaN           NaN\n",
       "      1987-01-01   NaN           NaN\n",
       "      1988-01-01   NaN           NaN\n",
       "      1989-01-01   NaN           NaN\n",
       "...                ...           ...\n",
       "WY    2019-01-01  8.12  3.997140e+10\n",
       "      2020-01-01  7.97  3.667550e+10\n",
       "      2021-01-01   NaN  4.217620e+10\n",
       "      2022-01-01   NaN  4.908060e+10\n",
       "      2023-01-01   NaN  5.017160e+10\n",
       "\n",
       "[1950 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efnagdp = pd.read_csv(\"EFNAGDPTaxes.csv\", parse_dates = [\"Year\"]).set_index([\"State\", \"Year\"]).sort_index()\n",
    "efnagdp[[\"EFNA\", \"GDP\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_keys = [\"GENERAL REVENUE\",\"GENERAL REVENUE FROM OWN SOURCES\", \"EXPENDITURE\", \"DEFICIT\", \n",
    "        \"FROM FEDERAL GOVERNMENT\", \"FROM STATE GOVERNMENT\", \"FROM LOCAL GOVERNMENTS\" ,\n",
    "        \"TAXES\", \"OTHER TAXES\", \"CURRENT CHARGES\", \"OTHER CHARGES\", 'INDIVIDUAL INCOME', 'CORPORATE INCOME', #'TOTAL INCOME',\n",
    "        \"PROPERTY\", \"SPECIAL ASSESSMENTS\"]\n",
    "        #\"PROPERTY AND SPECIAL ASSESSMENTS\",  \n",
    "        # \"SALES AND GROSS RECEIPTS\", \"GENERAL SALES\", \"MOTOR FUEL\", \"GAS SUPPLY\", \"EDUCATION\", \"HIGHER EDUCATION\", \"PUBLIC WELFARE\"]\t\n",
    "\n",
    "# keys = [\"GENERAL REVENUE\",\"GENERAL REVENUE FROM OWN SOURCES\", \"EXPENDITURE\", \"DEFICIT\", \n",
    "#         \"FROM FEDERAL GOVERNMENT\", \"FROM STATE GOVERNMENT\", \"FROM LOCAL GOVERNMENTS\" ,\n",
    "#         \"TAXES\", \"OTHER TAXES\", 'PROPERTY', 'SPECIAL ASSESSMENTS', 'PROPERTY AND SPECIAL ASSESSMENTS', 'SALES AND GROSS RECEIPTS', 'GENERAL SALES', 'SELECTIVE SALES', 'MOTOR FUEL', 'ALCOHOLIC BEVERAGE', \n",
    "#         'TOBACCO PRODUCTS', 'PUBLIC UTILITIES', 'OTHER SELECTIVE SALES', 'INDIVIDUAL INCOME', 'CORPORATE INCOME', \"TOTAL INCOME\", 'MOTOR VEHICLE LICENSE', \n",
    "#         'OTHER TAXES', 'CHARGES AND MISCELLANEOUS GENERAL  REVENUE', 'CURRENT CHARGES', 'EDUCATION', 'INSTITUTIONS  OF HIGHER EDUCATION', \n",
    "#         'SCHOOL LUNCH SALES (GROSS)', 'HOSPITALS', 'HIGHWAYS', 'AIR TRANSPORTATION (AIRPORTS)', 'PARKING FACILITIES', 'SEA AND INLAND PORT FACILITIES', \n",
    "#         'NATURAL RESOURCES', 'PARKS AND RECREATION', 'HOUSING AND COMMUNITY DEVELOPMENT', 'SEWERAGE', 'SOLID WASTE MANAGEMENT', 'OTHER CHARGES', \n",
    "#         'MISCELLANEOUS GENERAL REVENUE', 'INTEREST EARNINGS',  'SALE OF PROPERTY', 'OTHER GENERAL REVENUE', 'UTILITY REVENUE', \n",
    "#         'WATER SUPPLY', 'ELECTRIC POWER', 'GAS SUPPLY', 'TRANSIT', 'LIQUOR STORE REVENUE', 'INSURANCE TRUST REVENUE', 'UNEMPLOYMENT COMPENSATION', \n",
    "#         'EMPLOYEE RETIREMENT', \"WORKERS' COMPENSATION\", 'OTHER INSURANCE TRUST REVENUE',\"EDUCATION\", \"HIGHER EDUCATION\", \"PUBLIC WELFARE\"]\n",
    "# keys = [\"1\" + k for k in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dfs = {}\n",
    "keys = [\"GENERAL REVENUE\",\"GENERAL REVENUE FROM OWN SOURCES\", \"EXPENDITURE\", \"DEFICIT\", \n",
    "        \"FROM FEDERAL GOVERNMENT\", \"FROM STATE GOVERNMENT\", \"FROM LOCAL GOVERNMENTS\" ,\n",
    "        \"TAXES\", \"OTHER TAXES\", \"CURRENT CHARGES\", \"OTHER CHARGES\", 'INDIVIDUAL INCOME', 'CORPORATE INCOME', 'TOTAL INCOME',\n",
    "        \"PROPERTY\", \"SPECIAL ASSESSMENTS\", \"PROPERTY AND SPECIAL ASSESSMENTS\",  \n",
    "        \"SALES AND GROSS RECEIPTS\", \"GENERAL SALES\", \"MOTOR FUEL\", \"GAS SUPPLY\", \"EDUCATION\", \"HIGHER EDUCATION\", \"PUBLIC WELFARE\"]\t\n",
    "def set_plot_dfs(panel_dfs_dict, keys, efnagdp, cpi):\n",
    "    keys = [\"1\" + k for k in keys]\n",
    "    for key in panel_dfs_dict.keys():\n",
    "        plot_dfs[key] = {}\n",
    "        plot_dfs[key][\"Level\"] = panel_dfs_dict[key][keys].mul(10**3).copy()\n",
    "        plot_dfs[key][\"Level\"].rename(columns = {k:k.replace(\"1\", \"\").title() for k in plot_dfs[key][\"Level\"].keys()}, inplace = True)\n",
    "    #     plot_dfs[key][\"Level\"][\"Total Income\"] = plot_dfs[key][\"Level\"][\"Individual Income\"].add(plot_dfs[key][\"Level\"][\"Corporate Income\"])\n",
    "    #     plot_dfs[key][\"Level\"][\"Property and Special Assessments\"] = plot_dfs[key][\"Level\"][[\"Property\", \"Special Assessments\"]].sum(axis = 1)\n",
    "    #     plot_dfs[key][\"Level\"][\"Deficit\"] = plot_dfs[key][\"Level\"][\"Expenditure\"].sub(plot_dfs[key][\"Level\"][\"General Revenue\"])\n",
    "        plot_dfs[key][\"Level\"][\"GDP\"] = efnagdp[\"GDP\"]\n",
    "        plot_dfs[key][\"Real Level\"] = plot_dfs[key][\"Level\"].div(cpi[\"CPI\"], level = \"Year\", axis = 0)\n",
    "        plot_dfs[key][\"Level\"][\"Population\"] = efnagdp[\"Population\"]\n",
    "        plot_dfs[key][\"Percent of General Revenue\"] = plot_dfs[key][\"Level\"].apply(lambda x: pd.to_numeric(x).div(plot_dfs[key][\"Level\"][\"General Revenue\"]).mul(100))    \n",
    "        plot_dfs[key][\"Percent of GDP\"] = plot_dfs[key][\"Level\"].apply(lambda x: pd.to_numeric(x).div(plot_dfs[key][\"Level\"][\"GDP\"]).mul(100))\n",
    "        \n",
    "        plot_dfs[key][\"Real Value Per Capita\"] = plot_dfs[key][\"Real Level\"].apply(lambda x: pd.to_numeric(x).div(plot_dfs[key][\"Level\"][\"Population\"]))    \n",
    "        for key in plot_dfs.keys():\n",
    "            plot_dfs[key][\"Level\"][\"EFNA\"] = efnagdp[\"EFNA\"]\n",
    "    return plot_dfs\n",
    "plot_dfs = set_plot_dfs(panel_dfs_dict, keys, efnagdp, cpi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for key in plot_dfs:\n",
    "    try:\n",
    "        os.mkdir(f\"outputs/{key}\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_df = pd.read_csv(\"USCensusRegions.csv\")#.set_index(\"State\")\n",
    "# scatter_figs = {}\n",
    "for key, p_dfs in plot_dfs.items():\n",
    "    for p_dfskey, df in p_dfs.items():\n",
    "        map_figs = {}\n",
    "        html_path = f\"outputs/{key}/ScatterPlotsIncomePropertyAssessmentSalesFuelTaxesPctTotalRevenue{key}{p_dfskey}.html\"\n",
    "        create_scatter_dropdown(df, regions_df=regions_df,\n",
    "                                filename = html_path, \n",
    "                                show_fig = False)\n",
    "        for name in df.keys():\n",
    "            map_figs[name] = create_map(df.reset_index(), name, time_name = \"Year\")\n",
    "        combined_map_fig = combine_map_figs(map_figs)\n",
    "        html_path = f\"outputs/{key}/MapPlotsByVariableAndYear{key}{p_dfskey}.html\"\n",
    "        combined_map_fig.write_html(html_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dfs = {}\n",
    "keys = [\"GENERAL REVENUE\",\"GENERAL REVENUE FROM OWN SOURCES\", \"EXPENDITURE\", \"DEFICIT\", \n",
    "        \"FROM FEDERAL GOVERNMENT\", \"FROM STATE GOVERNMENT\", \"FROM LOCAL GOVERNMENTS\" , \"INTERGOVERNMENTAL REVENUE\",\n",
    "        \"TAXES\", \"OTHER TAXES\", 'PROPERTY', 'SPECIAL ASSESSMENTS', 'PROPERTY AND SPECIAL ASSESSMENTS', 'SALES AND GROSS RECEIPTS', 'GENERAL SALES', 'SELECTIVE SALES', 'MOTOR FUEL', 'ALCOHOLIC BEVERAGE', \n",
    "        'TOBACCO PRODUCTS', 'PUBLIC UTILITIES', 'OTHER SELECTIVE SALES', 'INDIVIDUAL INCOME', 'CORPORATE INCOME', \"TOTAL INCOME\", 'MOTOR VEHICLE LICENSE', \n",
    "        'OTHER TAXES', 'CHARGES AND MISCELLANEOUS GENERAL  REVENUE', 'CURRENT CHARGES', 'EDUCATION', 'INSTITUTIONS  OF HIGHER EDUCATION', \n",
    "        'SCHOOL LUNCH SALES (GROSS)', 'HOSPITALS', 'HIGHWAYS', 'AIR TRANSPORTATION (AIRPORTS)', 'PARKING FACILITIES', 'SEA AND INLAND PORT FACILITIES', \n",
    "        'NATURAL RESOURCES', 'PARKS AND RECREATION', 'HOUSING AND COMMUNITY DEVELOPMENT', 'SEWERAGE', 'SOLID WASTE MANAGEMENT', 'OTHER CHARGES', \n",
    "        'MISCELLANEOUS GENERAL REVENUE', 'INTEREST EARNINGS',  'SALE OF PROPERTY', 'OTHER GENERAL REVENUE', 'UTILITY REVENUE', \n",
    "        'WATER SUPPLY', 'ELECTRIC POWER', 'GAS SUPPLY', 'TRANSIT', 'LIQUOR STORE REVENUE', 'INSURANCE TRUST REVENUE', 'UNEMPLOYMENT COMPENSATION', \n",
    "        'EMPLOYEE RETIREMENT', \"WORKERS' COMPENSATION\", 'OTHER INSURANCE TRUST REVENUE',\"EDUCATION\", \"HIGHER EDUCATION\", \"PUBLIC WELFARE\"]\n",
    "plot_dfs = set_plot_dfs(panel_dfs_dict, keys, efnagdp, cpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_df = pd.read_csv(\"USCensusRegions.csv\")#.set_index(\"State\")\n",
    "\n",
    "for key, p_dfs in plot_dfs.items():\n",
    "    # figs = {k: line_dropdown(dataframe, regions_df) for k, dataframe in p_dfs.items()}\n",
    "    # fig = dict_of_line_figs_to_dropdown_fig(figs, show_fig = False, use_sliders = True)\n",
    "    filename = f\"outputs/{key}/LinePlotsStateFinancesAsPercentRevenuePercentGDPAndPerCapitaFigs{key}.html\"\n",
    "    fig = line_dropdown(p_dfs, regions_df)\n",
    "    fig.write_html(filename, config=dict(displayModeBar=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2005\n",
    "areas = {\"Revenue Source by Government\" : [\"General Revenue From Own Sources\", \"From Federal Government\", \"From State Government\", \"From Local Governments\"],\n",
    "         \n",
    "    #  Omit revenue sources according to distinction of subcomponents in revenue data \n",
    "    #  Some sources additionally needed to be removed as their values perfectly explained\n",
    "    #  accounting that sums to greater than 100 percent\n",
    "     \n",
    "         \"Taxes\": [\"Intergovernmental Revenue\", 'Property', 'Sales And Gross Receipts', \n",
    "                   'Individual Income', 'Corporate Income', 'Motor Vehicle License', 'Other Taxes', \n",
    "                #    'Charges And Miscellaneous General  Revenue', \n",
    "                   'Current Charges', \n",
    "                #    'Education', 'Institutions  Of Higher Education', 'School Lunch Sales (Gross)',\n",
    "                #      'Hospitals', 'Highways', 'Air Transportation (Airports)', 'Parking Facilities', 'Sea And Inland Port Facilities', 'Natural Resources',\n",
    "                #       'Parks And Recreation', 'Housing And Community Development', 'Sewerage', 'Solid Waste Management', 'Other Charges', \n",
    "                    #   'Miscellaneous General Revenue', \n",
    "                      'Interest Earnings', 'Special Assessments', 'Sale Of Property', 'Other General Revenue']}\n",
    "                    #   'Utility Revenue']}\n",
    "                    #   'Water Supply', 'Electric Power', 'Gas Supply', 'Transit', \n",
    "                    # 'Liquor Store Revenue',\n",
    "                #    'Insurance Trust Revenue',\n",
    "                #    'Unemployment Compensation', 'Employee Retirement', \"Workers' Compensation\", 'Other Insurance Trust Revenue']}\n",
    "figs = {}\n",
    "for key in plot_dfs.keys():\n",
    "    figs[key] = {}\n",
    "    for form, plot_df in plot_dfs[key].items():# [\"Level\", \"Real Level\", \"Percent of General Revenue\", \"Percent of GDP\", \"Real Value Per Capita\"]:\n",
    "        figs[key][form] = {}\n",
    "        df = plot_df.copy()\n",
    "        df = df.reset_index().melt(id_vars=[\"State\",\"Year\"],\n",
    "            var_name=\"Name\", \n",
    "            value_name=\"Value\")\n",
    "        df = df.set_index([\"State\", \"Year\"]).round(2)\n",
    "        states = df.index.get_level_values(\"State\").unique()\n",
    "\n",
    "        for components_group, components in areas.items():\n",
    "\n",
    "\n",
    "            figs[key][form][components_group] = {}\n",
    "\n",
    "            for state in states:\n",
    "                plot_df = df.loc[state].reset_index()#.loc[start_year:].reset_index()\n",
    "                plot_df = plot_df[plot_df[\"Name\"].isin(components)].dropna()\n",
    "                plot_df[\"Value\"] = pd.to_numeric(plot_df[\"Value\"])\n",
    "                title_key = f\"{components_group} {key}<br>{form}<br>{state}\"\n",
    "                px_fig = px.area(\n",
    "                    plot_df, x=\"Year\", y=\"Value\", color=\"Name\", title = title_key)\n",
    "\n",
    "                figs[key][form][components_group][state] = px_fig\n",
    "            figs[key][form][components_group]  = dict_of_figs_to_dropdown_fig(figs[key][form][components_group], \n",
    "                                                                              show_fig = False,\n",
    "                                                                              use_sliders = True)\n",
    "            figs[key][form][components_group].write_html(f\"outputs/{key}/AreaPlots{key}{form}{components_group}Figs.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliced_revenue = pd.read_csv(\"SplicedStateGovFinances.csv\")\n",
    "# spliced_revenue.set_index([\"State\", \"Year\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# folder = \"State government amount\"\n",
    "# frmt = \"LevelDiscrepancies\"\n",
    "# regions_df = pd.read_csv(\"USCensusRegions.csv\")#.set_index(\"State\")\n",
    "# # scatter_figs = {}\n",
    "# df = diff_df.copy()\n",
    "# map_figs = {}\n",
    "# create_scatter_dropdown(df, regions_df=regions_df,\n",
    "#                         filename = f\"outputs/{folder}/ScatterPlotsIncomePropertyAssessmentSalesFuelTaxesPctTotalRevenue{folder}{frmt}.html\", \n",
    "#                         show_fig = False)\n",
    "# for name in df.keys():\n",
    "#     map_figs[name] = create_map(df.reset_index(), name, time_name = \"Year\")\n",
    "# combined_map_fig = combine_map_figs(map_figs)\n",
    "# combined_map_fig.write_html(f\"outputs/{folder}/MapPlotsByVariableAndYear{folder}{frmt}.html\")\n",
    "\n",
    "#     # combined_scatter_fig = dict_of_figs_line_figs_to_dropdown_fig(scatter_figs,regions_df)\n",
    "\n",
    "\n",
    "# fig = line_dropdown(df, regions_df)\n",
    "# # fig.show()\n",
    "# fig.write_html(f\"outputs/{folder}/LinePlotsStateFinancesAsPercentRevenuePercentGDPAndPerCapitaFigs{folder}{frmt}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
